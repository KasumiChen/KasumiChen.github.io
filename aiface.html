<!DOCTYPE HTML>
<html>

<head>
	<title>Kris' Portfolio Site</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
</head>

<body class="is-preload">

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Header -->
		<header id="header" class="alt">
			<a href="index.html" class="logo"><strong>Kris'</strong> <span>Portfolio Site</span></a>
			<nav>
				<a href="#menu">Menu</a>
			</nav>
		</header>

		<!-- Menu -->
		<nav id="menu">
			<ul class="links">
				<li><a href="index.html">Home</a></li>
				<li><a href="bio.html">About Meee</a></li>
				<li><a href="https://www.instagram.com/kasumiii_art">Instagram</a></li>
				<li><a href="mailto:krischen.nekolabs@gmail.com">Contact</a></li>
			</ul>
			<!-- <ul class="actions stacked">
							<li><a href="#" class="button primary fit">Get Started</a></li>
							<li><a href="#" class="button fit">Log In</a></li>
						</ul> -->
		</nav>

		<!-- Main -->
		<div id="main" class="alt">

			<!-- One -->
			<section id="one">
				<div class="inner">
					<header class="major">
						<h1>Machine Learning Based Facial Motion Capture</h1>
					</header>

					<!-- Content -->
					<!-- <h2 id="content">Introduction</h2>
										<p>This was originally the mini-project 2 of my course 15664: Technical Animation taken at CMU. 
											Instead of simply making a demo in AMC Viewer, I decided to take this chance to make an actual cloth simulation system usable for my future games. 
										</p> -->
					<h2 id="content">Introduction & Motivation</h2>


					<div class="row">
						<div class="col-8 col-12-small">
							<p>In this project, I developed a Blender Add-on that enables users to animate facial expressions
								for characters.
								With this Add-on, users can create the character's facial animation by connecting a
								rigged model to it and utilizing their laptop's camera to capture their own facial
								movements and expressions with our Add-on's built-in neural network.
								<br>
								The Add-on will retarget the user's facial expressions to the character in real-time
								using our retargeting algorithm. I created various features including head movement,
								eyelid movement, brow movement, jaw and lip movementsâ€¦ Additionally, I have included
								various parameters that users can customize to tailor the Add-on's functionality to
								their liking.
								<br>
								(Btw I am the actor for all the motion captures here lol)
								<p>There are three main reasons for me to create this project:</p>
							</p>
						</div>
						<div class="col-4 col-12-small">
							<span class="image fit"><img src="images/aiface/all.gif" alt="" /></span>
						</div>
					</div>

					
					<div class="row">
						<div class="col-4 col-12-medium">
							<h5>Artificial Intelligence's Influence on Art and Technical Artists</h5>
							<p>AI's role in art, particularly in animation, is growing rapidly. Advanced AI models like DALLE, MidJourney, GPT-3, and Stable Diffusion are creating realistic images and animations. This shift promises to make animation production more efficient and cost-effective. My project explores the intersection of AI and traditional animation, marking my first step in this research area.
							</p>
						</div>
						<div class="col-4 col-12-medium">
							<h5>Facial Animation's Significance in Gaming and Media </h5>
							<p>Facial animations are vital in games and films, making characters more lifelike and emotionally relatable. Traditionally labor-intensive, new deep learning techniques and face landmark detection are simplifying the creation of realistic facial expressions. This evolution, exemplified by the rise of Virtual YouTubers like Hololive, has made animation more accessible and dynamic. I aim to deepen my knowledge and skills in facial animation by developing a tool for this purpose.
							</p>
						</div>
						<div class="col-4 col-12-medium">
							<h5>Technical Artist's Role in Art Pipeline and Tool Development </h5>
							<p>For technical artists, mastering art pipeline and tool creation is crucial. I'm focusing on learning Blender's technical aspects and its Python scripting API to create a Blender Add-on, enhancing my practical skills. Additionally, recognizing the lack of community-based facial animation tools for indie game developers, I aspire to lay the groundwork for an open-source facial animation tool, fostering collaboration and usage within the community.
							</p>
						</div>
					</div>

					<h2 id="content">Component Demo</h2>
					<div class="box alt">
						<div class="row gtr-50 gtr-uniform">
							<div class="col-3"><span class="image fit"><img src="images/aiface/brow.gif" alt="" />
								<div class="captionp">Brow Movement</div></span></div>
							<div class="col-3"><span class="image fit"><img src="images/aiface/head.gif" alt="" />
								<div class="captionp">Head Movement</div></span></div>
							<div class="col-3"><span class="image fit"><img src="images/aiface/eyelid.gif" alt="" />
								<div class="captionp">Eyelid Movement</div></span></div>
							<div class="col-3"><span class="image fit"><img src="images/aiface/mouse.gif" alt="" />
								<div class="captionp">Mouth Movement</div></span></div>
						</div>
					</div>

					<hr>

					<h2>Project Architecture</h2>

					<span class="image fit"><img src="images/aiface/arch.png" alt="" /></span>


					<h2>Implementation</h2>

					Here I introduce the Implementation of the core features:

					<h3>Control Panel</h3>
					<div class="row">
					
						<div class="col-4 col-12-small">
							The control panel is the user interface in blender, where I allow the user to fine-tune the
							motion capture weights to fit characters of different sizes and shape. In contrast, Users with different shape ans size of faces can also use the parameters to tune the the system to make the same facial movement of the users have the same impact over the characters.
						</div>
						<div class="col-2 col-12-small">
							<span class="image fit"><img src="images/aiface/panel.png" /></span>
						</div>
						<div class="col-6 col-12-small">
							<span class="image fit"><img src="images/aiface/panel_code.png" /></span>
						</div>
					</div>


					<h3>Openface Subprocess</h3>
					<p>
						A subprocess is initiated to launch a C++ openface instance to extract facial feature points shown in graph below. Then the data is sent between processes back to Blender through sockets.
					</p>
					<div class="row">
						<div class="col-4 col-12-small">
							<span class="image fit"><img src="images/aiface/openpose code.png" alt="" />
								<img src="images/aiface/network.png" alt="" /></span>

						</div>
						<div class="col-4 col-12-small">
							<span class="image fit"><img src="images/aiface/facial_landmarks_68markup.jpg" alt="" /></span>
						</div>
						<div class="col-4 col-12-small">
							<span class="image fit"><img src="images/aiface/aidetect.png" alt="" /></span>
						</div>
					</div>

					<h3>Retargeting</h3>
					<div class="row">
						<div class="col-4 col-12-small">
							<p>
								The feature points are finally retargeted to the prebuilt armature control nodes on the model. The feature points are first classified to represent different parts, then interpolated to the final movement.<br> 
								To gain stability and stable transitions in live animation, I used the Sliding Window Average to pre-process the data.
							</p>
						</div>
						<div class="col-4 col-12-small">
							<span class="image fit"><img src="images/aiface/retargetmodel.png" alt="" /></span>
						</div>
						<div class="col-4 col-12-small">
							<span class="image fit"><img src="images/aiface/retarget_code.png" alt="" /></span>
						</div>
					</div>

					<p>Fin.</p>

				</div>
			</section>
		</div>



		<!-- Footer -->
		<footer id="footer">
			<div class="inner">
				<!-- <ul class="icons"> -->
				<!-- <li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li> -->
				<!-- <li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li> -->
				<!-- <li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li> -->
				<!-- <li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li> -->
				<!-- <li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li> -->
				<!-- </ul> -->
				<ul class="copyright">
					<li>&copy; Kris Chen, 2023</li>
				</ul>
			</div>
		</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>